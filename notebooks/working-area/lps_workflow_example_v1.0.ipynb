{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24438183-d726-485c-8494-58aca7811a79",
   "metadata": {},
   "source": [
    "# **LPS - Workflow Example**\n",
    "\n",
    "In summary, this workflow contains:\n",
    "\n",
    "- Setup access to S3\n",
    "- Catalogue search using STAC API\n",
    "- Download a Sentinel-2 data product from S3\n",
    "- Run a simple SNAP workflow (Read, Subset, BandMath (NDVI)) in three ways:\n",
    "  - use the Java-Python mapping provided by Snappy\n",
    "  - use SNAP GPF operators with Snappy\n",
    "  - create and execute a SNAP GPF xml graph using SNAPISTA \n",
    "- Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b10c7c-5c44-4769-8fa0-44abb27cfead",
   "metadata": {},
   "source": [
    "## **1. Import Python packages**\n",
    "\n",
    "**Note:** The imports of *esa_snappy* and *snapista* may result in various Info/Warning/Error messages from SNAP core modules. They can be ignored here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9e0700d-a086-4c26-81a9-231a1bf42ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while parsing JAI registry file \"file:/opt/conda/envs/snap-cdse/esa-snap/snap/modules/org.esa.snap.snap-gpf/org-jaitools/jt-vectorize.jar!/META-INF/registryFile.jai\" :\n",
      "Error in registry file at line number #4\n",
      "A descriptor is already registered against the name \"Vectorize\" under registry mode \"rendered\"\n",
      "Error while parsing JAI registry file \"file:/opt/conda/envs/snap-cdse/esa-snap/snap/modules/ext/org.esa.snap.snap-core/org-geotools/gt-coverage.jar!/META-INF/registryFile.jai\" :\n",
      "Error in registry file at line number #31\n",
      "A descriptor is already registered against the name \"org.geotools.ColorReduction\" under registry mode \"rendered\"\n",
      "Error in registry file at line number #32\n",
      "A descriptor is already registered against the name \"org.geotools.ColorInversion\" under registry mode \"rendered\"\n",
      "Error while parsing JAI registry file \"file:/opt/conda/envs/snap-cdse/esa-snap/snap/modules/ext/org.esa.snap.snap-core/org-jaitools/jt-zonalstats.jar!/META-INF/registryFile.jai\" :\n",
      "Error in registry file at line number #4\n",
      "A descriptor is already registered against the name \"ZonalStats\" under registry mode \"rendered\"\n",
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/opt/conda/envs/snap-cdse/esa-snap/snap/modules/org.esa.snap.snap-netcdf/org-slf4j/slf4j-simple.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/opt/conda/envs/snap-cdse/esa-snap/snap/modules/ext/org.esa.snap.snap-netcdf/org-slf4j/slf4j-simple.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.slf4j.impl.SimpleLoggerFactory]\n",
      "INFO: org.esa.snap.core.gpf.operators.tooladapter.ToolAdapterIO: Initializing external tool adapters\n",
      "INFO: org.esa.snap.core.util.EngineVersionCheckActivator: Please check regularly for new updates for the best SNAP experience.\n"
     ]
    }
   ],
   "source": [
    "# General\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import sysconfig\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# S3 API\n",
    "import boto3\n",
    "\n",
    "# esa_snappy\n",
    "import esa_snappy\n",
    "\n",
    "# Snapista\n",
    "import snapista\n",
    "from snapista import Graph\n",
    "from snapista import Operator\n",
    "from snapista import TargetBand\n",
    "from snapista import TargetBandDescriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4b62a2-4728-481c-9125-a60bc2a69fc4",
   "metadata": {},
   "source": [
    "## **2. Get credentials for S3 access**\n",
    "Credentials created before in S3 keys manager dashboard, see here: https://eodata-s3keysmanager.dataspace.copernicus.eu/panel/s3-credentials.\n",
    "(This does not seem to work correctly for everyone: ok for PL, but not for OD. TODO: investigate)\n",
    "\n",
    "Therefore, we follow below an approach using temporary credentials.\n",
    "See details at https://documentation.dataspace.copernicus.eu/APIs/S3.html#example-script-to-download-product-using-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77de28e-3fc7-4bdf-88b0-51bcbb13642c",
   "metadata": {},
   "source": [
    "##### ***Configuration parameters:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5a9f68c-b5e4-4e54-bd39-7e9f66fbe071",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"auth_server_url\": \"https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token\",\n",
    "    \"odata_base_url\": \"https://catalogue.dataspace.copernicus.eu/odata/v1/Products\",\n",
    "    \"s3_endpoint_url\": \"https://eodata.dataspace.copernicus.eu\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8dd2a5-face-4e14-b994-dc4a578a3445",
   "metadata": {},
   "source": [
    "Before using this NB for the first time in a new server, create a .env file with your CDSE username/password:\n",
    "CDSE_USERNAME=myusername\n",
    "CDSE_PASSWORD=mypassword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1907169e-02cb-4687-817e-df0ae6dfb424",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "username = os.getenv('CDSE_USERNAME')\n",
    "password = os.getenv('CDSE_PASSWORD')\n",
    "#print(username)\n",
    "#print(password)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96687ea-45db-4598-b1e8-27fd6ff41da5",
   "metadata": {},
   "source": [
    "##### ***Retrieve an access token:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9c6a7ee-9a8d-4556-975e-0f7d69e69701",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "def get_access_token(config, username, password):\n",
    "    \"\"\"\n",
    "    Retrieve an access token from the authentication server.\n",
    "    This token is used for subsequent API calls.\n",
    "    \"\"\"\n",
    "    auth_data = {\n",
    "        \"client_id\": \"cdse-public\",\n",
    "        \"grant_type\": \"password\",\n",
    "        \"username\": username,\n",
    "        \"password\": password,\n",
    "    }\n",
    "    response = requests.post(config[\"auth_server_url\"], data=auth_data, verify=True, allow_redirects=False)\n",
    "    if response.status_code == 200:\n",
    "        return json.loads(response.text)[\"access_token\"]\n",
    "    else:\n",
    "        print(f\"Failed to retrieve access token. Status code: {response.status_code}\")\n",
    "        exit(1)\n",
    "\n",
    "###################################################################################################\n",
    "access_token = get_access_token(config, username, password)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8cfdfb-775e-443d-ab7e-efaf59ca0d39",
   "metadata": {},
   "source": [
    "##### ***Set up headers for API calls:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "096f8eb6-3a4a-48f0-9de6-4374f55e9b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {access_token}\",\n",
    "    \"Accept\": \"application/json\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea23689-0353-47d2-8cc9-fd791d6d8d04",
   "metadata": {},
   "source": [
    "##### ***Create temporary S3 credentials:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c2115ad-b946-4303-b637-3a9dc88ad73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporary S3 credentials created successfully.\n"
     ]
    }
   ],
   "source": [
    "###################################################################################################\n",
    "def get_temporary_s3_credentials(headers):\n",
    "    \"\"\"\n",
    "    Create temporary S3 credentials by calling the S3 keys manager API.\n",
    "    \"\"\"\n",
    "    credentials_response = requests.post(\"https://s3-keys-manager.cloudferro.com/api/user/credentials\", headers=headers)\n",
    "    if credentials_response.status_code == 200:\n",
    "        s3_credentials = credentials_response.json()\n",
    "        print(\"Temporary S3 credentials created successfully.\")\n",
    "        #print(f\"access: {s3_credentials['access_id']}\")\n",
    "        #print(f\"secret: {s3_credentials['secret']}\")\n",
    "        return s3_credentials\n",
    "    else:\n",
    "        print(f\"Failed to create temporary S3 credentials. Status code: {credentials_response.status_code}\")\n",
    "        print(\"Product download aborted.\")\n",
    "        exit(1)\n",
    "\n",
    "###################################################################################################\n",
    "s3_credentials = get_temporary_s3_credentials(headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781be85f-4f6a-4773-a719-3c0f2cdb30fa",
   "metadata": {},
   "source": [
    "## **3. Set up area and time interval of interest**\n",
    "The bounding box in `WGS84` coordinate system is `[(longitude and latitude coordinates of lower left and upper right corners)]`. \n",
    "You can get the bbox for a different area at the [bboxfinder](http://bboxfinder.com/) website.\n",
    "\n",
    "All requests require a bounding box to be given as an instance of `sentinelhub.geometry.BBox` with corresponding Coordinate Reference System (`sentinelhub.constants.CRS`). In our case it is in WGS84 and we can use the predefined WGS84 coordinate reference system from `sentinelhub.constants.CRS`.\n",
    "\n",
    "The selected area and time interval below will find just one product from the search: S2A_MSIL1C_20180803T103021_N0206_R108_T32UNE_20180803T142136, which includes the Hamburg area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7043be55-c11c-4ab2-bebd-f787996a01d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_coords_wgs84 = [9.8, 53.45, 10.25, 53.6]\n",
    "resolution = 60\n",
    "\n",
    "# Define a time interval of just 1 day:\n",
    "time_interval = \"2018-08-03\", \"2018-08-04\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef041bc-003c-47b1-8fcc-42c7862f31c7",
   "metadata": {},
   "source": [
    "## **4. Catalog API: init catalog and do the search**\n",
    "To search and discover data, we use the Catalog API. Sentinel Hub Catalog API (or shortly \"Catalog\") is an API implementing the STAC Specification, providing geospatial information for data available in Sentinel Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac786fc5-7643-4891-a893-991f26016483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3:/eodata/Sentinel-2/MSI/L1C_N0500/2018/08/03/S2A_MSIL1C_20180803T103021_N0500_R108_T32UNE_20230730T062418.SAFE'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pystac_client import Client\n",
    "from pathlib import Path\n",
    "\n",
    "catalog = Client.open('https://stac.dataspace.copernicus.eu/v1')\n",
    "collection = catalog.get_collection(\"sentinel-2-l1c\")\n",
    "collection.title\n",
    "\n",
    "itemsearch = catalog.search(\n",
    "    collections=[\"sentinel-2-l1c\"],\n",
    "    bbox=aoi_coords_wgs84,\n",
    "    datetime=[time_interval[0], time_interval[1]],\n",
    "\n",
    ")\n",
    "\n",
    "msil1c_results = list(itemsearch.items())\n",
    "base_s3_path = str(Path(msil1c_results[0].assets[\"product_metadata\"].href).parent)\n",
    "base_s3_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75649a8-4e99-43da-a5da-b49dfd2fc170",
   "metadata": {},
   "source": [
    "## **5. Download L1C SAFE product from S3**\n",
    "\n",
    "In this step, the product found from the search above is downloaded as file. This is necessary because the SNAP API needs a file representation of an input product.\n",
    "\n",
    "The download progress of each file of the SAFE product will be shown below. \n",
    "\n",
    "**Note:** Sometimes this step results in a '403 Forbidden' on CDSE Jupyter Hub. In that case just try to repeat... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d53e591d-10bf-4985-b1cc-23a2b48f696b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product ID: S2A_MSIL1C_20180803T103021_N0500_R108_T32UNE_20230730T062418\n"
     ]
    },
    {
     "ename": "ClientError",
     "evalue": "An error occurred (403) when calling the ListObjects operation: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#print(\"l1c_product_to_process: \" + l1c_product_to_process)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m l1c_files \u001b[38;5;241m=\u001b[39m bucket\u001b[38;5;241m.\u001b[39mobjects\u001b[38;5;241m.\u001b[39mfilter(Prefix\u001b[38;5;241m=\u001b[39ml1c_product_to_process)\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ml1c_files\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(l1c_files):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find any files for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ml1c_product_to_process\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/snap-cdse/lib/python3.10/site-packages/boto3/resources/collection.py:79\u001b[0m, in \u001b[0;36mResourceCollection.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m limit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlimit\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     78\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 79\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpages():\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m page:\n\u001b[1;32m     81\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m item\n",
      "File \u001b[0;32m/opt/conda/envs/snap-cdse/lib/python3.10/site-packages/boto3/resources/collection.py:169\u001b[0m, in \u001b[0;36mResourceCollection.pages\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# Now that we have a page iterator or single page of results\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# we start processing and yielding individual items.\u001b[39;00m\n\u001b[1;32m    168\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 169\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m pages:\n\u001b[1;32m    170\u001b[0m     page_items \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handler(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent, params, page):\n",
      "File \u001b[0;32m/opt/conda/envs/snap-cdse/lib/python3.10/site-packages/botocore/paginate.py:269\u001b[0m, in \u001b[0;36mPageIterator.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inject_starting_params(current_kwargs)\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 269\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m     parsed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extract_parsed_response(response)\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m first_request:\n\u001b[1;32m    272\u001b[0m         \u001b[38;5;66;03m# The first request is handled differently.  We could\u001b[39;00m\n\u001b[1;32m    273\u001b[0m         \u001b[38;5;66;03m# possibly have a resume/starting token that tells us where\u001b[39;00m\n\u001b[1;32m    274\u001b[0m         \u001b[38;5;66;03m# to index into the retrieved page.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/snap-cdse/lib/python3.10/site-packages/botocore/paginate.py:357\u001b[0m, in \u001b[0;36mPageIterator._make_request\u001b[0;34m(self, current_kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_make_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, current_kwargs):\n\u001b[0;32m--> 357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcurrent_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/snap-cdse/lib/python3.10/site-packages/botocore/client.py:569\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    566\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    567\u001b[0m     )\n\u001b[1;32m    568\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 569\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/snap-cdse/lib/python3.10/site-packages/botocore/client.py:1023\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1019\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1020\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1021\u001b[0m     )\n\u001b[1;32m   1022\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1023\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (403) when calling the ListObjects operation: Forbidden"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm  # For proper use in Jupyter NB, use tqdm.notebook instead of tqdm!! See https://www.datacamp.com/tutorial/tqdm-python\n",
    "\n",
    "##################################################################\n",
    "\n",
    "s3_resource=boto3.resource('s3',aws_access_key_id=s3_credentials[\"access_id\"], aws_secret_access_key=s3_credentials[\"secret\"], endpoint_url=config[\"s3_endpoint_url\"])\n",
    "\n",
    "# For processing, download S2 MSIL1C SAFE product from result list found above:\n",
    "l1c_product_to_process = msil1c_results[0]\n",
    "print(\"Product ID: \" + l1c_product_to_process.id)\n",
    "product_path = str(Path(l1c_product_to_process.assets[\"product_metadata\"].href).parent)\n",
    "\n",
    "prefix_length = len(\"s3://\") if product_path.startswith(\"s3://\") else len(\"s3:/\")\n",
    "bucketname = product_path[prefix_length : product_path.find(\"/\", prefix_length)]  # 'EODATA'\n",
    "prefix_length = prefix_length + len(bucketname) + 1\n",
    "\n",
    "bucket=s3_resource.Bucket(bucketname)\n",
    "\n",
    "target = \"./\"\n",
    "l1c_product_to_process = product_path[prefix_length:] # e.g. \"Sentinel-2/MSI/L1C_N0500/2018/08/03/S2A_MSIL1C_20180803T103021_N0500_R108_T32UNE_20230730T062418.SAFE/\"\n",
    "#print(\"l1c_product_to_process: \" + l1c_product_to_process)\n",
    "\n",
    "l1c_files = bucket.objects.filter(Prefix=l1c_product_to_process)\n",
    "list(l1c_files)\n",
    "if not list(l1c_files):\n",
    "    raise FileNotFoundError(f\"Could not find any files for {l1c_product_to_process}\")\n",
    "\n",
    "failed_downloads = []\n",
    "for file in l1c_files:\n",
    "    os.makedirs(os.path.dirname(file.key), exist_ok=True)\n",
    "\n",
    "    client = s3_resource.meta.client\n",
    "    s3_key = file.key\n",
    "    local_path = f\"{target}{file.key}\"\n",
    "    \n",
    "    try:\n",
    "        file_size = client.head_object(Bucket=bucketname, Key=s3_key)['ContentLength']\n",
    "        formatted_filename = os.path.basename(local_path) + ' '\n",
    "        with tqdm(total=file_size, unit='B', unit_scale=True, desc=formatted_filename, bar_format='{desc:.40}| {percentage:3.0f}% {n_fmt}/{total_fmt}B') as pbar:\n",
    "            def progress_callback(bytes_transferred):\n",
    "                pbar.update(bytes_transferred)\n",
    "    \n",
    "            client.download_file(bucketname, s3_key, local_path, Callback=progress_callback)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {s3_key}. Error: {e}\")\n",
    "        failed_downloads.append(s3_key)  # TODO: print list if length > 0\n",
    "\n",
    "if not failed_downloads:\n",
    "    print(\"Product download complete.\")\n",
    "else:\n",
    "    print(\"Product download incomplete:\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9303eb61-2a8a-46d3-9f8d-663009f7d2e3",
   "metadata": {},
   "source": [
    "##### ***Delete temporary S3 credentials:***\n",
    "\n",
    "After S3 access is no longer needed, we should remove the temporary S3 credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cec7592-3719-4f78-b00e-e3ae12e1c9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "def delete_temporary_s3_credentials(headers):\n",
    "    \"\"\"\n",
    "    Delete temporary S3 credentials by calling the S3 keys manager API.\n",
    "    \"\"\"\n",
    "    delete_response = requests.delete(f\"https://s3-keys-manager.cloudferro.com/api/user/credentials/access_id/{s3_credentials['access_id']}\", headers=headers)\n",
    "    if delete_response.status_code == 204:\n",
    "        print(\"Temporary S3 credentials deleted successfully.\")\n",
    "    else:\n",
    "        print(f\"Failed to delete temporary S3 credentials. Status code: {delete_response.status_code}\")\n",
    "\n",
    "###################################################################################################\n",
    "delete_temporary_s3_credentials(headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00144b6-77c0-4cf2-bdf9-a79e079c447b",
   "metadata": {},
   "source": [
    "## **6. Example of a workflow using the SNAP API from Python**\n",
    "\n",
    "The following simple example reads raster data from two bands (B4 and B8) of the downloaded S2 L1C product, computes/displays a simple NDVI, and saves the NDVI image as png."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96509c88-db67-458d-b160-329ec82e1b07",
   "metadata": {},
   "source": [
    "##### ***Some more imports:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e13d53-634f-4fe9-82f3-fee477038ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from esa_snappy import ProductIO  \n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad5008b-a43d-4e38-879c-a611e83942d1",
   "metadata": {},
   "source": [
    "##### ***Read the data product into SNAP:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beded511-cef2-4de7-9eb5-d0a1b9d3981b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = ProductIO.readProduct(l1c_product_to_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae336a1-3107-40ff-854a-9344488d85d9",
   "metadata": {},
   "source": [
    "##### ***Print some information:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da173cf0-19e3-4d5e-91fd-df7d870cc05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of bands: ' + str(p.getNumBands()))\n",
    "\n",
    "b4 = p.getBand('B4')\n",
    "w = b4.getRasterWidth()\n",
    "h = b4.getRasterHeight()\n",
    "print('Band B4 Raster width: ' + str(b4.getRasterWidth()))\n",
    "print('Band B4 Raster height: ' + str(b4.getRasterHeight()))\n",
    "print('Band B4 Wavelength: ' + str(b4.getSpectralWavelength()))\n",
    "print('Band B4 Spectral bandwidth: ' + str(b4.getSpectralBandwidth()))\n",
    "\n",
    "b8 = p.getBand('B8')\n",
    "w = b8.getRasterWidth()\n",
    "h = b8.getRasterHeight()\n",
    "print('Band B8 Raster width: ' + str(b8.getRasterWidth()))\n",
    "print('Band B8 Raster height: ' + str(b8.getRasterHeight()))\n",
    "print('Band B8 Wavelength: ' + str(b8.getSpectralWavelength()))\n",
    "print('Band B8 Spectral bandwidth: ' + str(b8.getSpectralBandwidth()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb467ec1-e5e3-4095-9cf3-f227daf16e91",
   "metadata": {},
   "source": [
    "##### ***Consider a 2000x2000 subset covering the center of Hamburg:***\n",
    "\n",
    "If possible, using a subset of area of interest and required bands is always recommended. Processing full S2 products might be rather time and memory consuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984be10a-d501-4e19-aaee-9080fb1af64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xoff = 5001\n",
    "yoff = 6001\n",
    "wsub = 2000\n",
    "hsub = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54357dff-7f20-407d-9064-3d59977503b2",
   "metadata": {},
   "source": [
    "##### ***Read the raster data into numpy arrays:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08130852-43f4-4cf8-a40c-45c0b5769368",
   "metadata": {},
   "outputs": [],
   "source": [
    "b4_data = np.zeros(wsub * hsub, np.float32)\n",
    "b4.readPixels(xoff, yoff, wsub, hsub, b4_data)\n",
    "b4_data.shape = hsub, wsub\n",
    "\n",
    "b8_data = np.zeros(wsub * hsub, np.float32)\n",
    "b8.readPixels(xoff, yoff, wsub, hsub, b8_data)\n",
    "b8_data.shape = hsub, wsub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcbd8a1-4928-4a75-88f4-2673b9d90e0b",
   "metadata": {},
   "source": [
    "##### ***Compute NDVI:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71331389-93b8-45ef-8ec0-0454048ba99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_data = (b4_data - b8_data) / (b4_data + b8_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dbfd5e-9528-4a07-9d74-e9084191fcd5",
   "metadata": {},
   "source": [
    "##### ***Display B4, B8, NDVI data:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6b1be8-e554-4cb3-9390-c7dc66894459",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, _axs = plt.subplots(nrows=1, ncols=2)\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "axs = _axs.flatten()\n",
    "\n",
    "axs[0].set_title(\"B4\")\n",
    "axs[0].tick_params(axis=\"both\", length=0, labelbottom=False, labelleft=False)\n",
    "axs[0].imshow(b4_data, cmap=mpl.colormaps['gray'], vmin=-0.1, vmax=0.5)\n",
    "\n",
    "axs[1].set_title(\"B8\")\n",
    "axs[1].tick_params(axis=\"both\", length=0, labelbottom=False, labelleft=False)\n",
    "axs[1].imshow(b8_data, cmap=mpl.colormaps['gray'], vmin=-0.1, vmax=0.5)\n",
    "\n",
    "plt.show(block=True)\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.set_title(\"NDVI\")\n",
    "ndvi_image = ax1.imshow(ndvi_data, cmap=mpl.colormaps['gray'], vmin=-0.7, vmax=0.1)\n",
    "fig1.colorbar(ndvi_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a480676-974c-495a-a965-8af96dc1554e",
   "metadata": {},
   "source": [
    "##### ***Write NDVI to png file:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84aeb7b-d19f-485a-94fc-3bc56ac834e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_image.write_png('ndvi_full.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2560836a-3442-4d46-8695-3c92d1b14f62",
   "metadata": {},
   "source": [
    "##### ***Dispose the product:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013813f1-1c95-4022-bb80-64b53a08766e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae5a7c0-c7a7-4b82-8f95-fca867134ada",
   "metadata": {},
   "source": [
    "# 7. Run the workflow using GPF and Snappy\n",
    "\n",
    "In this section we basically run the same workflow, but with means of the SNAP GPF framework and the SNAP Python API 'Snappy'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf2b03b-30b5-4135-93a6-f85f916dcc92",
   "metadata": {},
   "source": [
    "##### ***Some required imports from esa_snappy:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc735932-c0b9-4a61-8d51-3b3bf80efdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from esa_snappy import GPF\n",
    "from esa_snappy import HashMap\n",
    "from esa_snappy import Rectangle\n",
    "from esa_snappy import jpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d0f1ba-1c00-4d8a-9824-d64df5557596",
   "metadata": {},
   "source": [
    "##### ***Read L1C product again into SNAP:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52470758-c98a-40b8-9cf7-98e33c5c5bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = ProductIO.readProduct(l1c_product_to_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f868c5c4-f074-4266-8b64-7304d6a595e7",
   "metadata": {},
   "source": [
    "##### ***Set up a 'Subset' operator which considers the rectangle defined above:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f753a2e7-61ad-4fa1-bfdb-c34102bcfc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_op_name = 'Subset'\n",
    "subset_parameters = HashMap()\n",
    "subset_parameters.put('sourceBands', 'B4,B8')\n",
    "subset_rect = Rectangle(xoff,yoff,wsub,hsub)\n",
    "subset_parameters.put('region', subset_rect)\n",
    "subset_product = GPF.createProduct(subset_op_name, subset_parameters, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecabe28-45be-4ae8-a5d1-3704f63f0beb",
   "metadata": {},
   "source": [
    "##### ***Set up a 'BandMaths' operator to compute a simple NDVI. Set up a target band for NDVI result:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892d1b21-158c-4ad2-9554-56e87b6c7b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "bandmaths_op_name = 'BandMaths'\n",
    "BandDescriptor = jpy.get_type('org.esa.snap.core.gpf.common.BandMathsOp$BandDescriptor')\n",
    "ndvi_band = BandDescriptor()\n",
    "ndvi_band.name = 'ndvi'\n",
    "ndvi_band.type = 'float32'\n",
    "ndvi_band.expression = '(B4 - B8)/(B4 + B8)'\n",
    "target_bands = jpy.array('org.esa.snap.core.gpf.common.BandMathsOp$BandDescriptor', 1)\n",
    "target_bands[0] = ndvi_band\n",
    "bandmaths_parameters = HashMap()\n",
    "bandmaths_parameters.put('targetBands', target_bands)\n",
    "bandmaths_product = GPF.createProduct(bandmaths_op_name, bandmaths_parameters, subset_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a69f9e-423d-4e49-9d47-bd7edd5597d8",
   "metadata": {},
   "source": [
    "##### ***Additional step: Merge NDVI with bands of subset product :***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed85e56d-4eaf-4693-afe4-2aa31c8a0cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_op_name = 'BandMerge'\n",
    "merge_parameters = HashMap()\n",
    "merge_parameters.put('sourceBands', 'B4,B8,ndvi')\n",
    "source_products = HashMap()\n",
    "source_products.put('Subset', subset_product)\n",
    "source_products.put('BandMaths', bandmaths_product)\n",
    "merge_product = GPF.createProduct(merge_op_name, merge_parameters, source_products)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4544c570-9fd0-4b4b-bc8d-0c9ff88edb03",
   "metadata": {},
   "source": [
    "##### ***Additional step: Write Merge Subset result into a NetCDF file. This file can be downloaded and e.g. opened and visualized in SNAP Desktop:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f408132c-b95f-4454-8fcb-623d755ae550",
   "metadata": {},
   "outputs": [],
   "source": [
    "ProductIO.writeProduct(merge_product, './ndvi_result_snappy.nc', 'NetCDF4-BEAM')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6f4df1-9b4e-43e5-8721-43f62ff1abdc",
   "metadata": {},
   "source": [
    "##### ***Display NDVI result:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e4f8c5-e6fa-42f9-adf1-80fa2da92baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi = merge_product.getBand('ndvi')\n",
    "w = ndvi.getRasterWidth()\n",
    "h = ndvi.getRasterHeight()\n",
    "\n",
    "ndvi_data = np.zeros(w * h, np.float32)\n",
    "ndvi.readPixels(0, 0, w, h, ndvi_data)\n",
    "ndvi_data.shape = h, w\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.set_title(\"NDVI\")\n",
    "ndvi_image = ax1.imshow(ndvi_data, cmap=mpl.colormaps['gray'], vmin=-0.7, vmax=0.1)\n",
    "fig1.colorbar(ndvi_image)\n",
    "\n",
    "ndvi_image.write_png('ndvi.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd163ee4-5a8e-478c-86a9-1865f1709969",
   "metadata": {},
   "source": [
    "## **7. Run the workflow in an XML graph with Snapista**\n",
    "\n",
    "In this section we run the same workflow once again, but with means of the SNAP Python API 'SNAPISTA'. This will illustrate the capabilities of SNAPISTA to conveniently create, view, run and export SNAP GPT xml graphs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb929180-78da-4706-ab2c-f0e823a06e3c",
   "metadata": {},
   "source": [
    "#### **Fill a SNAPISTA graph with nodes:**\n",
    "\n",
    "##### ***Initialize the graph:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82b5bfb-1e2e-405d-8027-4a9a0acce844",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    g = Graph()\n",
    "except Exception as ex:\n",
    "    print(\"Cannot set up Snapista Graph():\", ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3b97e0-b7cb-44e1-9427-cf9151ccd881",
   "metadata": {},
   "source": [
    "##### ***Read L1C product again into SNAP:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f971b6ce-2fb4-4448-9730-7727863a49b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.add_node(operator=Operator(\"Read\", file=l1c_product_to_process), node_id=\"Read_l1c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6668d56e-a02a-4af9-a7e4-fcea6930143c",
   "metadata": {},
   "source": [
    "##### ***Set up a 'Subset' operator which considers the rectangle defined above:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a257860a-3118-4dd1-8eb9-1169dcbdd972",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = Operator('Subset', sourceBands=\"B4,B8\", region='5001, 6001, 2000, 2000')\n",
    "g.add_node(operator=subset, node_id=\"Subset\" ,source='Read_l1c')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6a5919-241b-47d1-b33f-d4d5626a34c4",
   "metadata": {},
   "source": [
    "##### ***Set up a 'BandMaths' operator to compute a simple NDVI. Set up a target band for NDVI result:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dedcc3-698e-40cb-b1f2-97c6a1e3d0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "band_maths = Operator('BandMaths')\n",
    "ndvi = TargetBand(name='ndvi', expression='(B4 - B8)/(B4 + B8)')\n",
    "band_maths.targetBandDescriptors = TargetBandDescriptors([ndvi])\n",
    "g.add_node(operator=band_maths, node_id=\"BandMaths\" ,source='Subset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86920a83-2ab5-4559-80ab-abb7ef2fdec5",
   "metadata": {},
   "source": [
    "##### ***Merge NDVI with bands of subset product:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fda0c1-bedc-44f8-8ed1-cb7bbdd00b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = Operator(\"BandMerge\", sourceBands=\"B4,B8,ndvi\")\n",
    "g.add_node(operator=merge, node_id=\"Merge\", source=[\"Subset\", \"BandMaths\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afc62a1-3207-4554-9b1e-80e41909c184",
   "metadata": {},
   "source": [
    "##### ***Write Merge Subset result into a NetCDF file:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e251c8-24d5-4d8b-a4d0-ef53a32a1712",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_ndvi = Operator(\"Write\", file='./ndvi_result_snapista.nc', formatName='NetCDF4-BEAM')\n",
    "g.add_node(operator=write_ndvi, node_id=\"WriteNdvi\", source='Merge')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d44e21-bd0c-4648-b9d7-cc5a0dedd256",
   "metadata": {},
   "source": [
    "##### ***Display the graph:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7578a0-49f1-4a24-8312-fdc582c67204",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7168f88d-dbcb-4ff2-9b98-366ce22ec7e2",
   "metadata": {},
   "source": [
    "##### ***Save the graph for potential use elsewhere:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8deaff2-13db-42de-a846-c521c7a974f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.save_graph('./lps_workflow_example_graph.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad2b1ec-6e48-4e7d-929a-d2cfe1d3309f",
   "metadata": {},
   "source": [
    "##### ***Run the graph using the SNAPISTA GPT wrapper:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf9334a-3bd6-45c7-83d9-832297de04f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcb3c8c-69a1-42fb-8b08-5af1e26ed367",
   "metadata": {},
   "source": [
    "## **8. Compare SNAPISTA NDVI result with the one from Snappy**\n",
    "\n",
    "##### ***Read SNAPISTA NDVI result NetCDF back into SNAP:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf96cdb9-4559-47c0-9e4d-1b914276097b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_snapista_product = ProductIO.readProduct('./ndvi_result_snapista.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9259850f-d069-4ece-a28a-500fe7017237",
   "metadata": {},
   "source": [
    "##### ***Display NDVI result:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebce7d99-2bb1-42f3-833e-68e30aa2aad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi = ndvi_snapista_product.getBand('ndvi')\n",
    "w = ndvi.getRasterWidth()\n",
    "h = ndvi.getRasterHeight()\n",
    "\n",
    "ndvi_data = np.zeros(w * h, np.float32)\n",
    "ndvi.readPixels(0, 0, w, h, ndvi_data)\n",
    "ndvi_data.shape = h, w\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.set_title(\"NDVI\")\n",
    "ndvi_image = ax1.imshow(ndvi_data, cmap=mpl.colormaps['gray'], vmin=-0.7, vmax=0.1)\n",
    "fig1.colorbar(ndvi_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896c0cbe-dd79-4a56-9759-48d4bb994cd2",
   "metadata": {},
   "source": [
    "## **9. Cleanup**\n",
    "To save workspace on CDSE, we should finally remove the downloaded source product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3256f7ba-ca16-49fe-aac2-0ae53e9d0d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cleanup...')\n",
    "print(subprocess.call([\"rm\", \"-Rf\", l1c_product_to_process]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26beb688-2a1f-4210-85a0-33eb23f8f539",
   "metadata": {},
   "source": [
    "## **10. Summary**\n",
    "\n",
    "What have we learnt in this notebook?\n",
    "\n",
    "- How to quickly access satellite imagery using STAC Catalogue API and S3 download.\n",
    "- How to read a Sentinel-2 L1C product into SNAP\n",
    "- How to build and run a SNAP gpt graph using SNAP Python API (esa_snappy, Snapista)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593d6e5e-14bd-475d-b418-d90131453643",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ESA SNAP)",
   "language": "python",
   "name": "snap-cdse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
